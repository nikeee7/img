{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unified_class</th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Оленевые</td>\n",
       "      <td>5</td>\n",
       "      <td>3cf4207b958eade893a2f1618cf062b8.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Кошки</td>\n",
       "      <td>2</td>\n",
       "      <td>37698901280c871f426d40afe5c373cd.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Заяц</td>\n",
       "      <td>0</td>\n",
       "      <td>20e7b30026001cbfe0b5c0ee16c9ff56.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Кошки</td>\n",
       "      <td>2</td>\n",
       "      <td>a1bc8ea546206ee8fc0f1836fda9a5c1.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Оленевые</td>\n",
       "      <td>5</td>\n",
       "      <td>54eb76914b84db8a0d56f98125abf588.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28010</th>\n",
       "      <td>Оленевые</td>\n",
       "      <td>5</td>\n",
       "      <td>07b420b4fe265b4ed918b46435c025d7.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28011</th>\n",
       "      <td>Пантеры</td>\n",
       "      <td>6</td>\n",
       "      <td>2d1c5918357bbdd729bf79085e55d35e.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28012</th>\n",
       "      <td>Заяц</td>\n",
       "      <td>0</td>\n",
       "      <td>1531efa9f8687e390adf780355acd606.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28013</th>\n",
       "      <td>Кабан</td>\n",
       "      <td>1</td>\n",
       "      <td>2b15eaef0ce9b57b6570709f95a4bea4.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28014</th>\n",
       "      <td>Пантеры</td>\n",
       "      <td>6</td>\n",
       "      <td>d1fec8a6b6be63534c37f0a26e94c7e8.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28015 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unified_class  class_id                            image_name\n",
       "0          Оленевые         5  3cf4207b958eade893a2f1618cf062b8.JPG\n",
       "1             Кошки         2  37698901280c871f426d40afe5c373cd.JPG\n",
       "2              Заяц         0  20e7b30026001cbfe0b5c0ee16c9ff56.JPG\n",
       "3             Кошки         2  a1bc8ea546206ee8fc0f1836fda9a5c1.JPG\n",
       "4          Оленевые         5  54eb76914b84db8a0d56f98125abf588.JPG\n",
       "...             ...       ...                                   ...\n",
       "28010      Оленевые         5  07b420b4fe265b4ed918b46435c025d7.JPG\n",
       "28011       Пантеры         6  2d1c5918357bbdd729bf79085e55d35e.JPG\n",
       "28012          Заяц         0  1531efa9f8687e390adf780355acd606.JPG\n",
       "28013         Кабан         1  2b15eaef0ce9b57b6570709f95a4bea4.JPG\n",
       "28014       Пантеры         6  d1fec8a6b6be63534c37f0a26e94c7e8.JPG\n",
       "\n",
       "[28015 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df.class_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3cf4207b958eade893a2f1618cf062b8.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37698901280c871f426d40afe5c373cd.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20e7b30026001cbfe0b5c0ee16c9ff56.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>a1bc8ea546206ee8fc0f1836fda9a5c1.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>54eb76914b84db8a0d56f98125abf588.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28010</th>\n",
       "      <td>5</td>\n",
       "      <td>07b420b4fe265b4ed918b46435c025d7.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28011</th>\n",
       "      <td>6</td>\n",
       "      <td>2d1c5918357bbdd729bf79085e55d35e.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28012</th>\n",
       "      <td>0</td>\n",
       "      <td>1531efa9f8687e390adf780355acd606.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28013</th>\n",
       "      <td>1</td>\n",
       "      <td>2b15eaef0ce9b57b6570709f95a4bea4.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28014</th>\n",
       "      <td>6</td>\n",
       "      <td>d1fec8a6b6be63534c37f0a26e94c7e8.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28015 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class_id                            image_name\n",
       "0             5  3cf4207b958eade893a2f1618cf062b8.JPG\n",
       "1             2  37698901280c871f426d40afe5c373cd.JPG\n",
       "2             0  20e7b30026001cbfe0b5c0ee16c9ff56.JPG\n",
       "3             2  a1bc8ea546206ee8fc0f1836fda9a5c1.JPG\n",
       "4             5  54eb76914b84db8a0d56f98125abf588.JPG\n",
       "...         ...                                   ...\n",
       "28010         5  07b420b4fe265b4ed918b46435c025d7.JPG\n",
       "28011         6  2d1c5918357bbdd729bf79085e55d35e.JPG\n",
       "28012         0  1531efa9f8687e390adf780355acd606.JPG\n",
       "28013         1  2b15eaef0ce9b57b6570709f95a4bea4.JPG\n",
       "28014         6  d1fec8a6b6be63534c37f0a26e94c7e8.JPG\n",
       "\n",
       "[28015 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['unified_class'], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc27b9b56583a615fb8501e352402eb9.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87872711fe672676fd34a97e997f9c47.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>424aa1aa8eb5bbdd07275f88077bc86c.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c5537eaa60525efd7bad4a5560607e83.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e9f15b67ca49453e281b2b4f245eac13.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12953</th>\n",
       "      <td>028668e733cd17ec9b9f1c7e2c657b36.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12954</th>\n",
       "      <td>eb1f1152941fdfdd50ff9954010e622a.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12955</th>\n",
       "      <td>bfd2dde9f4a5753c9f85b2a93bee9c03.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12956</th>\n",
       "      <td>2eaf9c794958a93bb9984441fd5d7f61.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12957</th>\n",
       "      <td>720558d15a8fd14ae5d0301d901b58cd.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12958 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_name  predicted_class\n",
       "0      cc27b9b56583a615fb8501e352402eb9.JPG                0\n",
       "1      87872711fe672676fd34a97e997f9c47.JPG                0\n",
       "2      424aa1aa8eb5bbdd07275f88077bc86c.JPG                0\n",
       "3      c5537eaa60525efd7bad4a5560607e83.JPG                0\n",
       "4      e9f15b67ca49453e281b2b4f245eac13.JPG                0\n",
       "...                                     ...              ...\n",
       "12953  028668e733cd17ec9b9f1c7e2c657b36.JPG                0\n",
       "12954  eb1f1152941fdfdd50ff9954010e622a.JPG                0\n",
       "12955  bfd2dde9f4a5753c9f85b2a93bee9c03.JPG                0\n",
       "12956  2eaf9c794958a93bb9984441fd5d7f61.JPG                0\n",
       "12957  720558d15a8fd14ae5d0301d901b58cd.JPG                0\n",
       "\n",
       "[12958 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, labels, dir_path=None):\n",
    "        super().__init__()\n",
    "        self.paths = paths\n",
    "        self.dir_path = dir_path\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        \n",
    "        # img = torchvision.io.read_image(self.dir_path+self.paths[ind]) / 255\n",
    "        img = Image.open(self.dir_path+self.paths[ind]).convert('RGB')\n",
    "        \n",
    "        transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize((256, 256)),\n",
    "            torchvision.transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        img = transforms(img)\n",
    "        \n",
    "        return img, self.labels[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    paths = df['image_name'].tolist(),\n",
    "    labels = df['class_id'].tolist(),\n",
    "    dir_path = 'train/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28015"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9333, 0.9333, 0.9333,  ..., 0.4549, 0.6431, 0.8078],\n",
       "          [0.9373, 0.9373, 0.9373,  ..., 0.6627, 0.7451, 0.7686],\n",
       "          [0.9451, 0.9451, 0.9451,  ..., 0.8745, 0.8588, 0.7804],\n",
       "          ...,\n",
       "          [0.9686, 0.9686, 0.9686,  ..., 0.9686, 0.9686, 0.9686],\n",
       "          [0.9647, 0.9647, 0.9647,  ..., 0.9647, 0.9647, 0.9647],\n",
       "          [0.9608, 0.9608, 0.9608,  ..., 0.9608, 0.9608, 0.9608]],\n",
       " \n",
       "         [[0.9647, 0.9647, 0.9647,  ..., 0.4784, 0.6667, 0.8353],\n",
       "          [0.9686, 0.9686, 0.9686,  ..., 0.6824, 0.7647, 0.7922],\n",
       "          [0.9765, 0.9765, 0.9765,  ..., 0.8941, 0.8824, 0.8039],\n",
       "          ...,\n",
       "          [0.9843, 0.9843, 0.9843,  ..., 0.9843, 0.9843, 0.9843],\n",
       "          [0.9804, 0.9804, 0.9804,  ..., 0.9804, 0.9804, 0.9804],\n",
       "          [0.9765, 0.9765, 0.9765,  ..., 0.9765, 0.9765, 0.9765]],\n",
       " \n",
       "         [[0.9765, 0.9765, 0.9765,  ..., 0.6118, 0.7882, 0.9216],\n",
       "          [0.9804, 0.9804, 0.9804,  ..., 0.7843, 0.8471, 0.8667],\n",
       "          [0.9882, 0.9882, 0.9882,  ..., 0.9490, 0.9333, 0.8667],\n",
       "          ...,\n",
       "          [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],\n",
       "          [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],\n",
       "          [0.9882, 0.9882, 0.9882,  ..., 0.9882, 0.9882, 0.9882]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.class_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df.class_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "#for param in model.parameters():\n",
    "#    param.require = False\n",
    "model.fc = nn.Linear(512, 10)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9091, 1.3553, 2.8645, 3.5642, 1.1117, 0.2416, 0.6216, 1.4142, 1.5078,\n",
       "        3.7008], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(df.class_id), y=df.class_id)\n",
    "# weight = torch.FloatTensor(weight).to(device)\n",
    "# weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.CrossEntropyLoss(weight = weight)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # для scheduler\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7b373524a5461d8e07e349822c91e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 0.4239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5edd0e41e0f49a58a1054e53cc9e71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 0.1775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db458a91565450ebd61f4f78b686b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 0.1481\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc9553568fa49aaa1568b28208e8e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.0871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c82dc66e18b46dcb7273b98578b06cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.0659\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9449c9f18a4113825e8a8da2a9449b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.0758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1b4a610ed94186a8c4ea7d6af90bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.0612\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f445846dcb4994afe9ff71ec0b7c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.0516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbdcca84fc841e0be41d97aca82053c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.0373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56080872924e43d4b492774de2da9159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.0450\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    i=0\n",
    "    \n",
    "    for data in tqdm(dataloader):\n",
    "        i+=1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # if i % 219 == 218:    # print every 2000 mini-batches\n",
    "        #     print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 219:.4f}')\n",
    "        #     running_loss = 0.0\n",
    "\n",
    "    print(f'epoch {epoch + 1}, train loss: {running_loss / len(dataloader):.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, dir_path=None):\n",
    "        super().__init__()\n",
    "        self.paths = paths\n",
    "        self.dir_path = dir_path\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        \n",
    "        # img = torchvision.io.read_image(self.dir_path+self.paths[ind]) / 255\n",
    "        img = Image.open(self.dir_path+self.paths[ind]).convert('RGB')\n",
    "        \n",
    "        transforms = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize((256, 256)),\n",
    "            torchvision.transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        img = transforms(img)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = testDataset(\n",
    "    paths = sample['image_name'].tolist(),\n",
    "    dir_path = 'test/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0078, 0.0078, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0157, 0.0157, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0235, 0.0235, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0314, 0.0118, 0.1176,  ..., 0.0784, 0.0863, 0.1137],\n",
       "         [0.0275, 0.0196, 0.0706,  ..., 0.0706, 0.0745, 0.0980],\n",
       "         [0.0235, 0.0275, 0.3020,  ..., 0.0118, 0.0118, 0.0235]],\n",
       "\n",
       "        [[0.0078, 0.0078, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0157, 0.0157, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0235, 0.0235, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0314, 0.0118, 0.1176,  ..., 0.0784, 0.0863, 0.1137],\n",
       "         [0.0275, 0.0196, 0.0706,  ..., 0.0706, 0.0745, 0.0980],\n",
       "         [0.0235, 0.0275, 0.3020,  ..., 0.0118, 0.0118, 0.0235]],\n",
       "\n",
       "        [[0.0078, 0.0078, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0157, 0.0157, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0235, 0.0235, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0235, 0.0078, 0.1098,  ..., 0.0784, 0.0863, 0.1137],\n",
       "         [0.0196, 0.0157, 0.0627,  ..., 0.0706, 0.0745, 0.0980],\n",
       "         [0.0196, 0.0275, 0.2941,  ..., 0.0118, 0.0118, 0.0235]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.array(list(set(df.class_id)))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a27ccad6b5f41bfa76881186639d5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12958 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Counter({5: 4673,\n",
       "         6: 2494,\n",
       "         4: 1308,\n",
       "         8: 957,\n",
       "         1: 937,\n",
       "         7: 863,\n",
       "         0: 546,\n",
       "         2: 485,\n",
       "         9: 361,\n",
       "         3: 334})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = [''] * len(testloader)\n",
    "    i=0\n",
    "    for X in tqdm(testloader):\n",
    "        X = X.to(torch.float).to(device)\n",
    "        pred[i] = classes[model(X)[0].argmax(0)]\n",
    "        i+=1\n",
    "Counter(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc27b9b56583a615fb8501e352402eb9.JPG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87872711fe672676fd34a97e997f9c47.JPG</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>424aa1aa8eb5bbdd07275f88077bc86c.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c5537eaa60525efd7bad4a5560607e83.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e9f15b67ca49453e281b2b4f245eac13.JPG</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12953</th>\n",
       "      <td>028668e733cd17ec9b9f1c7e2c657b36.JPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12954</th>\n",
       "      <td>eb1f1152941fdfdd50ff9954010e622a.JPG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12955</th>\n",
       "      <td>bfd2dde9f4a5753c9f85b2a93bee9c03.JPG</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12956</th>\n",
       "      <td>2eaf9c794958a93bb9984441fd5d7f61.JPG</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12957</th>\n",
       "      <td>720558d15a8fd14ae5d0301d901b58cd.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12958 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_name  predicted_class\n",
       "0      cc27b9b56583a615fb8501e352402eb9.JPG                4\n",
       "1      87872711fe672676fd34a97e997f9c47.JPG                5\n",
       "2      424aa1aa8eb5bbdd07275f88077bc86c.JPG                0\n",
       "3      c5537eaa60525efd7bad4a5560607e83.JPG                1\n",
       "4      e9f15b67ca49453e281b2b4f245eac13.JPG                6\n",
       "...                                     ...              ...\n",
       "12953  028668e733cd17ec9b9f1c7e2c657b36.JPG                1\n",
       "12954  eb1f1152941fdfdd50ff9954010e622a.JPG                4\n",
       "12955  bfd2dde9f4a5753c9f85b2a93bee9c03.JPG                5\n",
       "12956  2eaf9c794958a93bb9984441fd5d7f61.JPG                6\n",
       "12957  720558d15a8fd14ae5d0301d901b58cd.JPG                0\n",
       "\n",
       "[12958 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['predicted_class'] = pred\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
